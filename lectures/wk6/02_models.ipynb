{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models II: Univariate Regression with `statsmodels`\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "In the previous notebook we calculated a GLM by-hand by implementing the OLS solution using `numpy`.  \n",
    "In this notebook we're going to meet [`statsmodels`](https://www.statsmodels.org/stable/index.html) a new Python library that allows us to much more easily *estimate*, *evaluate*, and *compare* models to each other.\n",
    "\n",
    "We won't be covering the full functionality of `statsmodels` as it's vast and beyond the scope of this course.  \n",
    "Instead we'll be focusing on estimating regression models using [OLS in statsmodels](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html#statsmodels.regression.linear_model.OLS-parameters) which behaves very similarily to `lm()`in R.\n",
    "\n",
    "- Estimating a univariate regression using OLS with `statsmodels`\n",
    "- Evaluating and inspecting model assumptions and predictions\n",
    "- Testing simple hypotheses using model comparison\n",
    "- Interpeting estimated model parameters\n",
    "- Understanding parameter inference\n",
    "\n",
    "## Slides for reference\n",
    "\n",
    "[Modeling Data I (slides)](https://stat-intuitions.com/lectures/wk5/1.html)  \n",
    "[Modeling Data II (slides)](https://stat-intuitions.com/lectures/wk5/2.html)  \n",
    "[Modeling Data II 1/2 (slides)](https://stat-intuitions.com/lectures/wk5/3.html)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Regression\n",
    "\n",
    "Let's learn how to fit a univariate regression model using `statsmodels`. \n",
    "\n",
    "We'll be using a dataset of credit-card scores that contains observations from 400 different people with the following columns:\n",
    "\n",
    "| Variable   | Description                     |\n",
    "|------------|---------------------------------|\n",
    "| Income     | in thousand dollars            |\n",
    "| Limit      | credit limit                    |\n",
    "| Rating     | credit rating                   |\n",
    "| Cads      | number of credit cards          |\n",
    "| Age        | in years                        |\n",
    "| Education  | years of education              |\n",
    "| Gender     | male or female                  |\n",
    "| Student    | student or not                  |\n",
    "| Married    | married or not                  |\n",
    "| Ethnicity  | African American, Asian, Caucasian |\n",
    "| Balance    | average credit card debt        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from polars import col\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = pl.read_csv('./data/credit.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary question we're interested in answering is: \n",
    "\n",
    "**Is there a relationship between *Income* (how much a person makes) and their *Balance* (average credit card debt)?**\n",
    "\n",
    "$$\n",
    "Balance_i = \\beta_0 + \\beta_1 Income_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember univariate regression is just a \"flavor\" of the GLM where we only have a single predictor variable $X$ being used to model an outcome variable $y$.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./figs/uni_regress.png\" width=\"30%\" alt=\"Figure 1\">\n",
    "</div>\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Exploration\n",
    "\n",
    "Before you build any model you should **always plot your data first**. This will give you better idea of what your data looks like any any modeling choices you might make.  \n",
    "\n",
    "Let's use `seaborn` to plot our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt # for customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df,\n",
    "    x='Income',\n",
    "    y='Balance',\n",
    "    color='black',\n",
    "    alpha=.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there does seem to be some kind of relationship: as income increases so does balance.  \n",
    "There's also some interesting observations at the lower end of income let's zoom into those.  \n",
    "I'll first filter the data to Incomes < 50 and then create another scatter plot + a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows and only select 3 columns\n",
    "df_lt_50 = df.filter(col('Income') < 50).select(['Index', 'Income','Balance'])\n",
    "\n",
    "# Create 1 x 2 figure\n",
    "f, axs = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Left\n",
    "sns.scatterplot(\n",
    "    data=df_lt_50,\n",
    "    x='Income',\n",
    "    y='Balance',\n",
    "    color='black',\n",
    "    alpha =.25,\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "# Right\n",
    "sns.histplot(df_lt_50, x='Balance', ax=axs[1]);\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine();\n",
    "\n",
    "# Add overall title\n",
    "f.suptitle('Balances for Income < 50');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, we can see that for a large number of people with Incomes below this threshold they carry a **Balance** of $0!  \n",
    "Let's keep this mind as we fit our model and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's ask `seaborn` to add in a regression line using the original data.  \n",
    "This gives us an indication of how well our model will do before we use `statsmodels`.  \n",
    "In fact, `seaborn` *uses* `statsmodels` under-the-hood to do regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data=df, # original data\n",
    "    x='Income',\n",
    "    y='Balance',\n",
    "    fit_reg=True,\n",
    "    ci=None, # no confidence intervals\n",
    "    scatter_kws={'color':'black', 'alpha':.25}, # match color scatterplots\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this is promising and verifies out visual intuitions about an increasing linear relationship. Let's go ahead and estimate a model ourselves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model estimation\n",
    "\n",
    "We can start by importing the `ols` function from `statsmodels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes 2 arguments:\n",
    "\n",
    "- `formula`: a Python string that specifies the model using formula-syntax similar to R's `lm()` function\n",
    "- `data`: a Pandas DataFrame that contains the data; we can convert our `polars` DataFrame to a Pandas DataFrame using `.to_pandas()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on using model \"formulas\"\n",
    "\n",
    "Wilkinson Notation, i.e. \"formula syntax\" was [popularized by R](https://www.econometrics.blog/post/the-r-formula-cheatsheet/) and provides a succinct way to specify models.  \n",
    "`statsmodels` supports [*mostly* the same syntax](https://www.statsmodels.org/stable/example_formulas.html) but there are a [few differences](https://patsy.readthedocs.io/en/latest/R-comparison.html) you should be aware of in-case you're trying to translate things 1-to-1\n",
    "\n",
    "We'll try to add any formula quirks to the course-website, but for now this reference should get you going:\n",
    "\n",
    "| Formula   | Description                     |\n",
    "|------------|---------------------------------|\n",
    "| `y ~ 1`    | intercept only             |\n",
    "| `y ~ x1`   | intercept and x1                |\n",
    "| `y ~ 0 + x1` | only x1 without intercept                   |\n",
    "| `y ~ np.log(x1)`   | intercept and log-transformed x1                |\n",
    "| `y ~ center(x1)`   | intercept and mean-centered x1                |\n",
    "| `y ~ standardize(x1)`   | intercept and z-scored x1                |\n",
    "| `y ~ x1 + x2`      | intercept, x1, and x2          |\n",
    "| `y ~ x1 + x2+ x1:x2`     | intercept, x1, x2, and their interaction                        |\n",
    "| `y ~ x1*x2`  | short-hand for previous              |\n",
    "| `y ~ x1 + x1**2`      | intercept, x1, and x2 squared                  | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this syntax to define our model. `statsmodels` works best with Pandas dataframes so make to call `.to_pandas()` on your dataframe before passing it to `ols`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('Balance ~ Income', data=df.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that whenever we use formula syntax, both R and Python will automatically add an intercept term for us. In other words, the following formulas are equivalent:\n",
    "\n",
    "- `Balance ~ 1 + Income`\n",
    "- `Balance ~ Income`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key model attributes\n",
    "\n",
    "The `model` variable we created is a `statsmodels` OLS model that has 2 key attributes you'll want to know how to access:\n",
    "\n",
    "1. `model.exog`: the $X$ design matrix of the model\n",
    "2. `model.endog`: the $y$ vector of observations of the dependent variable\n",
    "\n",
    "*Note `statsmodels` was developed in an econometrics tradition where [$X$ is referred to as the \"exogenous\" variable and $y$ is referred to as the \"endogenous\" variable](https://www.statsmodels.org/stable/endog_exog.html).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our **design matrix** contains a column for the intercept $\\beta_0$ and column for our single predictor $\\beta_1$ **Income**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 3 rows of design matrix\n",
    "model.exog[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that our $y$ vector is just the column of our dependent variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy function to compare two arrays each element at a time\n",
    "np.allclose(\n",
    "    model.endog,\n",
    "    df['Balance'].to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually estimate our model, we can use its `.fit()` method and save the output to a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Estimation Attributes\n",
    "\n",
    "The output of `.fit()` is a [`RegressionResults`](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.RegressionResults.html#statsmodels.regression.linear_model.RegressionResults) object that has lots of methods and attributes referenced in the linked documentation.\n",
    "\n",
    "For now let's just focus on a few of you're most likely to use:\n",
    "\n",
    "- `results.params`: the estimated $\\hat{\\beta}$ coefficients\n",
    "- `results.fittedvalues`: the predicted values $\\hat{y}_i$\n",
    "- `results.resid`: the residuals $y_i - \\hat{y}_i$\n",
    "- `results.ssr`: the sum of the squared residuals $\\sum_{i=1}^n (y_i - \\hat{y}_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betas - estimated coefficients\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get each one by name by *slicing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params['Intercept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params['Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the model's predictions of our dependent variable ($\\hat{y}$), in this case $\\hat{Balance}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values of Balance\n",
    "results.fittedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Pandas Series (single DataFrame column) by default so it can be helpful to convert it to a `numpy` array for future operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = results.fittedvalues.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also get the model **residuals** or differennce between the observed and predicted values:\n",
    "\n",
    "$$ residual_i = y_i - \\hat{y}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same thing as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Balance'].to_numpy() - results.fittedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarily convert this DataFrame column to a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = results.resid.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels` also gives us the SSE of the model, which it calls the sum-of-the-squared-residuals (SSR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of squared residuals\n",
    "results.ssr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can manually verify ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(results.resid ** 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interpreting Parameter Estimates\n",
    "\n",
    "Let's take a look at the estimated $\\beta$ values and try to understand what they mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look back at the plot we made earlier to understand exactly what these estimates refer to\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./figs/lmplot.png\" width=\"50%\" alt=\"Figure 1\">\n",
    "</div>\n",
    "\n",
    "In natural language we would state:\n",
    "\n",
    "\"*For each additional thousand dollars of income, a person's average credit card debt is expected to increased b $6.05*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute I thought the **Intercept** was always the *mean* of $y$, what gives?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What parameters mean\n",
    "\n",
    "The key lesson to remember when interpeting parameter estimates from *any* GLM is:\n",
    "\n",
    "The expected change in $y$ for 1-unit of change in $x_i$ **when all other model parameters are fixed at 0**, this is when $x_{not\\ i} = 0$.  \n",
    "\n",
    "In other words, our Intercept value of $246.5$ is our prediction for $\\hat{Balance}$ when $Income = 0$ !\n",
    "\n",
    "Does this make sense for an estimate we want? More importantly **is this even in the range of the observed data**?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(df['Income']);\n",
    "ax.vlines(x=0, ymin=0, ymax=ax.get_ylim()[-1], ls='--', color='k', label='Assumed value for Income when interpreting Intercept');\n",
    "ax.set(xlabel='Income', title='Distribution of Incomes')\n",
    "plt.legend();\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, interpreting our **Intercept** parameter is essentially meaningless because we never actually observed an individual with an Income of 0!  \n",
    "The take-away here is the models will happily **make predictions outside the range of your data** but often times this isn't what you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving interpretations with centering\n",
    "\n",
    "What we really want is for our model to estimate an **Intercept** that assumes **Income** is fixed at some *reasonable value* that we measured. How can we do this?  \n",
    "Easy! We can just *center* our predictor around some meaningful value by subtracting it from each data-point.  \n",
    "Most commonly, you'll want to **mean-center** your predictors - which makes the **Intercept** more interpretable!  \n",
    "\n",
    "Let's try it out and see what happens. Let's add a mean-centered **Income** column to our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    Income_centered = col('Income') - col('Income').mean(),\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's estimate a new model with this column and look at its parameter estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_centered = ols('Balance ~ Income_centered', data=df.to_pandas())\n",
    "results_centered = model_centered.fit()\n",
    "\n",
    "results_centered.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow the Intercept changed! What's going on? How about a visual inspection with `seaborn`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.lmplot(\n",
    "    data=df,\n",
    "    x='Income_centered',\n",
    "    y='Balance',\n",
    "    fit_reg=True,\n",
    "    ci=None,\n",
    "    scatter_kws={'color':'black', 'alpha':.25},\n",
    "    truncate=False\n",
    ")\n",
    "grid.ax.vlines(0, 0, 2000, linestyle='--', color='black', lw=2)\n",
    "grid.ax.hlines(520, -40, 150, linestyle='--', color='black', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've added dashed black lines to the figure to illustrate the effect of centering **Income**.  \n",
    "From the perspective of the model, $\\beta_0$ is now the estimate of the **Intercept** when **Income** is held constant at its **mean value**.  \n",
    "If we draw a vertical line at the new mean of **Income_centered**, i.e. 0 we can see where it *intercepts* the regression line.  \n",
    "This *is* our new estimated $\\beta_0 = 520.015$ !\n",
    "\n",
    "And just to verify that this is indeed the mean of $y$, let's just calculate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    col('Balance', 'Income', 'Income_centered').mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy centering with `statsmodels` formulas\n",
    "\n",
    "We can actually do this very easily in `statsmodels` *without* having to create a DataFrame column by using `center` inside our formula.  \n",
    "\n",
    "This is a special operation `statsmodels` understands that saves us time. Below I'm not saving any outputs or the model itself but just printing the estimated parameters so you can see that they're the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols('Balance ~ center(Income)', data=df.to_pandas()).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take aways about centering\n",
    "\n",
    "We'll discuss centering more when we look at *multiple regression* in a later notebook, but for now here are some key take-aways:\n",
    "\n",
    "- Centering is a way to fix a parameter estimate at some value (e.g. mean) to aid in the interpretation of *other parameter estimates* \n",
    "- Centering never changes the parameter estimate of the variable *being centered*\n",
    "- It only changes the value of *other parameter estimates*\n",
    "- You should *almost always* consider centering your continuous variable unless a value of 0 is of theoretical interest!\n",
    "- Centering is *incredibly important* in multiple regression with interactions, but we'll cover this in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation\n",
    "\n",
    "`statsmodels` has made it pretty easy to estimate a model, but before we make strong conclusions about our parameter estimates, we should always at least visually inspect that we're not violating the course assumptions of the GLM: **independent and identitically distributed (iid) errors**. \n",
    "\n",
    "We can do this by inspecting the **residuals** from our model and looking for any structure in the errors that our model makes.\n",
    "\n",
    "Let's do this in 3 ways:\n",
    "\n",
    "1. We'll start by looking at the distribution of residuals using a historgram and QQplot and checking they're approximately normal (they should be)\n",
    "2. We'll plot the residuals against the predictor variable **Income** looking for any structure in how the *errors vary with the predictor* (they shouldn't)\n",
    "3. We'll look at the residuals against the true value of **Balance** looking for any values our dependent variable that are particulary mis-predicted by our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by adding columns that contain the residuals to our DataFrame to make plotting easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    residuals = results.resid.to_numpy(),\n",
    "    residuals_centered = results_centered.resid.to_numpy(),\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrubtion of Residuals\n",
    "\n",
    "#### Residual Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the residuals are approximately normal, but there's a peak between -500 and -250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.displot(data=df,x='residuals',height=5,aspect=1.5, kde=True)\n",
    "grid.set_axis_labels('Residuals','Count');\n",
    "grid.figure.suptitle('Residuals from: Balance ~ Income');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also true if we plot the residuals from our centered model because centering *doesn't change the prediction accuracy* of a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.displot(data=df,x='residuals_centered',height=5,aspect=1.5, kde=True)\n",
    "grid.set_axis_labels('Residuals','Count');\n",
    "grid.figure.suptitle('Residuals from Balance ~ Income_centered');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual QQPlots\n",
    "Another useful way to examine the distribution of your residuals that can supplement a histogram is a QQ plot.  \n",
    "This is a plot of the quantiles of the residuals against the theoretical quantiles of a standard normal distribution.  \n",
    "\n",
    "We can do this using the `qqplot` function from `statsmodels` which takes DataFrame column or array of residuals as input. The `line = s` tells `qqplot` to add in a red identity line across standard normal quantiles.\n",
    "\n",
    "If our residuals were *perfectly* normally distributed, then they would lie right on the red identity line.  \n",
    "Deviations above or below the line tell you how far away from normality the residuals are.  \n",
    "\n",
    "Overall, this QQplot looks pretty good. But we can see that towards the low end of data values, it veers upwards - similar to the spike we saw in the histogram.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import it \n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "# Pass it the column that contains the residuals\n",
    "qqplot(df['residuals'], line = 's');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's helpful to see the *standardized residuals* instead, especially if you wanted to compare QQplots with different scales. \n",
    "\n",
    "To do so we can use the `results` from our `model.fit()` and call the `.get_influence()` method on it. This returns a few different things, but we care about `.resid_studentized`, which converts our residuals to an approximately standard-deviation scale.\n",
    "\n",
    "In this case the QQplot looks pretty much the same, but notice how the y-axis is now in units of standard-deviation instead of raw data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized are sometimes easier to compare across models\n",
    "qqplot(results.get_influence().resid_studentized, line = 's');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals and Predictors\n",
    "#### Residual Scatterplots\n",
    "\n",
    "Let's see if we can figure out what that peak is. It might help to plot the residuals against the predictor $X$ **Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(data=df, height=4,aspect=1.5)\n",
    "\n",
    "# Residuals vs Income\n",
    "grid.map(sns.scatterplot, 'Income', 'residuals', color='steelblue');\n",
    "\n",
    "# Horizontal line at 0\n",
    "grid.map(plt.axhline, y=0, color='gray', linestyle='--');\n",
    "\n",
    "# Labels and legend\n",
    "grid.set_axis_labels('Income', 'Residuals');\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed we can see that most of the error in our model is coming from the mis-predicted observations from people with an $Income < 50$\n",
    "\n",
    "Since so many people below this threshold carry a **Balance** of $0, there's no *variance* in the $y$ values our model observes and therefore it can't incorporate this into the parameter estimates!\n",
    "\n",
    "Our errors are therefore due to a lack of variance in that region of the data itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on `sns.residplot`\n",
    "\n",
    "`seaborn` offers a handy axis-level function called [`sns.residplot`](https://seaborn.pydata.org/generated/seaborn.residplot.html) that can be used to plot residuals even before you've fitted a model. \n",
    "\n",
    "It can be handy for exploring simple univariate regression models because `seaborn` will automatically estimate an `ols` model and calculate the residuals for you give the column that corresponds to your $X$ variable and a column that corresponds to your $y$ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.residplot(\n",
    "    data=df,\n",
    "    x='Income',\n",
    "    y='Balance', # Give it the column of the DV directly!\n",
    "    scatter_kws={'color':'black', 'alpha':.25},\n",
    ")\n",
    "\n",
    "ax.set(xlabel='Income', ylabel='Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general thought, I find `sns.residplot` a bit in-flexible and prefer to create my own figures using other `seaborn` functions by adding columns to my DataFrame and plotting those like we did before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals and Outcomes\n",
    "#### Inspecting Model Predictions\n",
    "\n",
    "Finally it's always a good idea to plot the predictions of our model $\\hat{Balance}$ against our observed values of $Balance$.  \n",
    "Let's add a column to our DataFrame and visualize the relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    Balance_predictions = results.fittedvalues.to_numpy()\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.relplot(\n",
    "    data=df,\n",
    "    x=\"Balance\",\n",
    "    y=\"Balance_predictions\",\n",
    "    kind='scatter',\n",
    "    height=5,\n",
    "    aspect=1.5,\n",
    ")\n",
    "\n",
    "# Labels and legend\n",
    "grid.set_axis_labels('Balance (measured)', 'Balance (predicted)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient of Determination ($R^2$)\n",
    "\n",
    "We can quantify the quality of our predictions by calculating the **coefficient of determination**.\n",
    "\n",
    "The coefficient of determination, often denoted as $R^2$, measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "$$ R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} $$\n",
    "\n",
    "Where:\n",
    "- $SS_{\\text{res}}$ is the residual sum of squares, $e^Te$.\n",
    "- $SS_{\\text{tot}}$ is the total sum of squares, adjusting for the mean, $(y-\\bar{y})^T(y-\\bar{y})$.\n",
    "\n",
    "A value of $R^2$ close to 1 suggests that a large proportion of the variability in the outcome has been explained by the regression model.  \n",
    "A value close to 0 indicates the model is missing a large amount of variability in the outcome  \n",
    "A value *below* 0 indicates the model is *systematically* mis-predicting in some way\n",
    "\n",
    "We can use the handy `r2_score` function from the `sklearn` library to calculate this for us. We haven't discussed this library yet, but we'll come back to it later.\n",
    "\n",
    "`r2_score` takes in two arguments:\n",
    "- `y_true`: the true values of the dependent variable\n",
    "- `y_pred`: the predicted values of the dependent variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(df['Balance'].to_numpy(), df['Balance_predictions'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in fact we can see that this matches the output that `statsmodels` gives us in its `.rsquared` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Inspect models of Anscombe's Quartet\n",
    "\n",
    "In the following cell we've loaded Anscombe's quarted for you into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anscombe = pl.DataFrame(sns.load_dataset('anscombe')) \n",
    "anscombe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Using `.filter()` in polars, create 4 new dataframes, one per dataset, and fit 4 separate `ols` models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Visualize the residuals of each model using a `qqplot` \n",
    "\n",
    "    How do these compare to plots of the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison\n",
    "\n",
    "Now that we've seen how to estimate a model using `ols` how do we know whether the slope we're observing between **Income** and **Balance** is meaningful? \n",
    "\n",
    "In class we learned that we can formulate our hypotheses as **model comparisons**, i.e. comparing a *compact* model to an *augmented* model and asking whether the **trade-off** between adding more parameters and the proportional reduction in error (PRE) is **worth it**.\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./figs/model_comparison.png\" width=\"90%\" alt=\"Figure 1\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Manual Way: Building Intuitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to implement this using `statsmodels` ourselves. We already have our *augmented* model that includes **Income** as predictor. So let's create and fit a *compact* model that doesn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with only an intercept term - i.e. mean of Balance\n",
    "compact_model = ols(\"Balance ~ 1\", data=df.to_pandas())\n",
    "compact_results = compact_model.fit()\n",
    "\n",
    "# Same as our model above, just redefining it here for clarity\n",
    "# 2 parameters: Intercept + Slope of Income\n",
    "augmented_model = ols(\"Balance ~ Income\", data=df.to_pandas())\n",
    "augmented_results = augmented_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate our PRE using the SSE of each model. Remember we can access this using the `.ssr` attribute of a model's results object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_c = compact_results.ssr\n",
    "error_a = augmented_results.ssr\n",
    "\n",
    "PRE = (error_c - error_a) / error_c\n",
    "\n",
    "print(f\"Proportional Reduction in Error: {PRE:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that adding **Income** as a predictor reduces our SSE in predicting **Balance** by about 21%.  \n",
    "This estimate is the same as our **coefficient of variation** ($R^2$) from earlier!  \n",
    "It turns out for *univariate regression only*, the PRE is identical to the coefficient of variation!\n",
    "\n",
    "That seems good, but is it **worth it**?\n",
    "\n",
    "To answer this question we need to know the *sampling distribution* of PRE - i.e. how *uncertain* we are about this single PRE we calculated. Had we collected another dataset, our PRE could be a bit different...\n",
    "\n",
    "We could use what we learned about **resampling** to calculate this distribution, but we'll explore that later...  \n",
    "\n",
    "For now,  a shortcut we can exploit is that the sampling distribution of PRE is awfully similar to the sampling distribution of the F-statistic (see above image).  \n",
    "In fact we can convert between the two, and get the **analytic sampling distribution**  as follows:\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./figs/fstat.png\" width=\"50%\" alt=\"Figure 1\">\n",
    "</div>\n",
    "\n",
    "Let's calculate that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 2 # intercept + slope\n",
    "pc = 1 # intercept only\n",
    "n = df.height\n",
    "\n",
    "F = (PRE / (pa - pc)) / ((1 - PRE) / (n - pa)) \n",
    "\n",
    "print(f\"PRE to F: {PRE:.2f} to {F:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look up the analytic sampling distribution and calculate a p-value we can use `scipy` which contains many different types of [distributions](https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions). We'll import the F distribution and look for proportion of values equal to greater than our observed F-statistic.\n",
    "\n",
    "We can use the **cumulative distribution function** of the F-statistic as our sampling distribution - this is a distribution of *probabilities* that F will take on some value given some \"degrees of freedom.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "# Difference in number of model degrees of freedom = difference in number of parameters\n",
    "model_df = pa - pc\n",
    "\n",
    "# Error df = number of observations - number of model parameters in augmented model\n",
    "error_df = df.height - pa\n",
    "\n",
    "pval = 1 - f.cdf(F, model_df, error_df)\n",
    "\n",
    "print(f\"Proportion Reduction of Error: = {PRE:3f}, F = {F:3f}, p = {pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize this sampling distribution we can use the following helper function provided by your instructors.\n",
    "\n",
    "But with such a large F-statistic the rejection region is off the plot - it's very *worth it* to add this additional parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import plot_F_sampling_distribution\n",
    "plot_F_sampling_distribution(PRE, F, pval, pa, pc, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside on degrees of freedom\n",
    "\n",
    "Ok let's take a second to try to understand degrees of freedom (df) a little better. DF is the number of dimensions along which a quantity can vary. For example, let’s say we have the following data points for a variable $x: [3, 5, 7, 9, 11]$, and estimate the sample mean which is $7$. With this estimate in hand, we can recover any single value if it were missing. \n",
    "\n",
    "For example, let’s say we didn't know what the first value was: $x: [nan, 5, 7, 9, 11]$\n",
    "\n",
    "Using the mean we estimated, $7$, we know that this value *must* be $3$. It's value is \"fixed\" and thus determined by the rest of the values and the mean we calculated. Why? Because the mean of $7$ implies that the sum of all of the values is $7 * n = 35$. And $35 - (5 + 7 + 9 + 11) = 3$.\n",
    "\n",
    "When you think/read about \"losing\" or \"consuming\" a degree of freedom, it means that there is an observation who's  value that is no longer free to vary after estimating a parameter. This is why we often \"correct\" for degrees of freedom in sample statistics, like the sample variance by dividing by $n-1$:\n",
    "\n",
    "\n",
    "$$\\sigma^2_x = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the sample variance $\\sigma_x^2$ is a function of the sample mean $\\bar{x}$, we have 1 data-point who's value is *fixed* based upon is *this particular* sample mean. Hence the true number of *independent* observations we have is $n-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degrees of freedom in GLM\n",
    "\n",
    "In the GLM, degrees-of-freedom are associated with both the *independent parameters* (**model df**) and *independent errors* (**error df**).\n",
    "\n",
    "**Model df** (or \"numerator df\") is generally equal to the number of parameters $p$, assuming none of the predictors in X are redundant. For our compact model, $p = 1$ because we're only estimating 1 parameter, the intercept.  \n",
    "Likewise, for our augmented model $p = 2$ because we're estimating *both* an intercept *and* a slope.\n",
    "\n",
    "**Error df** (or \"denominator df\"), assuming the errors are independent, is the number of observations ($n$) minus the number of model parameters estimated ($p$). For our compact model this is $400 - 1$ and for our augmented model it is $400 - 2$.\n",
    "\n",
    "Using these values we can using the `f.cdf` function like we did above to calculate the p-value associated with our calculated F-statistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Easier Way: What you'll do in practice\n",
    "\n",
    "Fortunately `statsmodels` has a built-in function to automate this process for us: `anova_lm()`. This function takes 1 or more results from fitted `ols` models and compares them in the same way we just did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to a quirk of how statsmodels was made, we need to import and use anova_lm() like this\n",
    "import statsmodels.api as sm \n",
    "\n",
    "sm.stats.anova_lm(compact_results, augmented_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we get the same F-statistic and p-value as before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Inference: Meet `.summary()`\n",
    "\n",
    "Up until now we've been manually accessing the various attributed of the results from a fitted model, e.g. `results.ssr`.  \n",
    "Of course, like R `statsmodels` can provide all these values plus additional information in a handy *summary*.\n",
    "\n",
    "We can use the `.summary()` method on a results object to get all of these statistics plus more in a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I find it a bit easier to read the summary table if you put it inside a print() function\n",
    "print(augmented_results.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [website](https://www.geeksforgeeks.org/interpreting-the-results-of-linear-regression-using-ols-summary/) has a comprehensive breakdown of this output.  \n",
    "\n",
    "But let's highlight the key statistics that we've been focusing on so far and remind ourselves what they mean:\n",
    "\n",
    "- $F\\ statistic$: the `F` value we calculated using the PRE\n",
    "- $DF\\  Residuals$: number of observations (400) minus the number of parameters (2) we estimated\n",
    "- $Prob\\ (F\\ statistic)$: the `pval` value we calculated using analytic sampling distribution of `F`\n",
    "- $\\beta_0$: the `coef` value of the `Intercept`\n",
    "- $\\beta_1$: the `coef` value of the `Income`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Inference as nested model comparison\n",
    "\n",
    "We haven't talked about what the $t$ or $std err$ of each parameter means yet, but you might notice that for **Income**, the statistic $t$ is equal to $\\sqrt{F}$, i.e. $10.44 = \\sqrt{108.99}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(results.fvalue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tvalues['Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that when we talk about performing statistical inference on a **parameter estimate**, it's proportional to performing a comparison between 2 **nested models**:\n",
    "\n",
    "- a *compact model* with some parameters\n",
    "- an *augmented model* with all the same parameters *plus* a new one we want to make an inference about, e.g. $Income$ \n",
    "\n",
    "In other words, testing the hypothesis that the slope of **Income** in predicting **Balance** is different that 0:\n",
    "\n",
    "$$\n",
    "H_0: \\beta_1 = 0 \\\\\n",
    "H_1: \\beta_1 \\neq 0 \\\\\n",
    "$$\n",
    "\n",
    "is equivalent to testing whether the proporational reduction in error (PRE), between two models, that differ only in that parameter, is *worth it*:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "H_0: \\hat{Balance}_i &= \\hat{\\beta_0} \\\\\n",
    "H_1: \\hat{Balance}_i &= \\hat{\\beta_0} + \\hat{\\beta_1} Income_i \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In a later notebook we'll talk about how to perform parameter inference using the **uncertainty** of each $\\hat{\\beta}$ estimate (i.e. it's standard-error), but the interpretation doesn't really change! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Wrap-up\n",
    "\n",
    "### Reporting Results\n",
    "\n",
    "Putting it all together we might write up our results like this:\n",
    "\n",
    "*We observed, a significant relationship between a person's income and the average balance on their credit cards F(1, 389) = 108.99, p < .001, r = .463.*  \n",
    "*With each additional $1000 of income, a person's average balance is predicted to increase by $6.05 [4.91 7.19]*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=df, x='Income', y='Balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we met `statsmodels` which allowed us to much more easily estimate univariate regression models using `ols`. \n",
    "We also learned how to evaluation a model by inspecting its residuals and fitted values using `seaborn`.  \n",
    "Finally we demonstrated how we can test hypotheses by comparing modes to each other.  \n",
    "And how parameter inference (whether or not a parameter is statistically different from 0) is equivalent to comparing 2 models with and without the parameter.\n",
    "\n",
    "Here's a list of basic steps you may want to keep in mind as we move forward with multiple regression and categorical predictors later this week:\n",
    "\n",
    "1. Define a model using `ols()` and a formula\n",
    "2. Estimate a model `.fit()` and save the results to a variable\n",
    "3. Inspect attributes of the saved results and use `seaborn` to plot them and evaluate model assumptions\n",
    "4. Formulate hypotheses as nested-model comparisons between a compact and augmented model and use `anova_lm()` to compare them\n",
    "5. Inspect parameter inferences *after* model selection using `.summary()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Use the same DataFrame of credit-card scores to estimate and interpret the relationship between a person's **Age** and their **Balance**.  \n",
    "We've reloaded it for you below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('./data/credit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Visually explore the data\n",
    "\n",
    "Does anything seem strange about the values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Estimate a univariate regression\n",
    "\n",
    "Use the `statsmodels` to estimate a simple univariate regression model that captures:\n",
    "\n",
    "$$\n",
    "Balance_i = \\beta_0 + \\beta_1 Age_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Evaluate the model\n",
    "\n",
    "Make some figures of the residuals and write a sentence or two describing them and what concerns you have if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test the hypothesis\n",
    "\n",
    "Test the hypothesis that **Age** is statistically significant predictor of **Balance** using model comparison.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Inspect the model summary\n",
    "\n",
    "Use `.summary()` to inspect the model summary. How does the output relate to your model comparison in the previous step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "201b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
